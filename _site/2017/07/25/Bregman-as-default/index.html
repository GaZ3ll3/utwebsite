<html>
  <head>
    <meta content='Bregman As Default? - Welcome to Yimin's Homepage' property='og:title' />
    <title>Bregman As Default? - Welcome to Yimin's Homepage</title>
    <link href='/users/yzhong/images/fav.png' rel='shortcut icon'>
<link href='http://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css' />
<link href='/users/yzhong/stylesheets/style.css' rel='stylesheet' type='text/css' />
<link href='/users/yzhong/stylesheets/syntax.css' rel='stylesheet' type='text/css' />
<link href='/users/yzhong/stylesheets/responsive.css' rel='stylesheet' type='text/css' />
<!-- <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.css" rel='stylesheet' type='text/css'/> -->

<div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
        }
    });

    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        processEscapes: true
        }
    });

    MathJax.Hub.Queue(function() {
        // Fix <code> tags after MathJax finishes running. This is a
        // hack to overcome a shortcoming of Markdown. Discussion at
        // https://github.com/mojombo/jekyll/issues/199
        var all = MathJax.Hub.getAllJax(), i;
        for(i = 0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });

    MathJax.Hub.Config({
      config: ["MMLorHTML.js"],
      jax: ["input/TeX","input/MathML","output/HTML-CSS","output/NativeMML", "output/CommonHTML"],
      extensions: ["tex2jax.js","mml2jax.js","MathMenu.js","MathZoom.js", "CHTML-preview.js"],
      TeX: {
      extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
      }
    });
</script>

</div>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js"></script>
<!-- <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/katex.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.5.1/contrib/auto-render.min.js"></script> -->

<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_SVG"></script>
<script type="text/javascript" src="https://www.google.com/jsapi"></script>
<!-- - -->
<meta content='width=device-width, initial-scale=1.0, user-scalable=no' name='viewport'>
<meta content='text/html; charset=utf-8' http-equiv='content-type' />
<meta content="/users/yzhong/image/fav.png" property="og:image" />
<meta content="" property="fb:app_id" />

<meta content='http://www.ma.utexas.edu/users/yzhong/2017/07/25/Bregman-as-default/' property='og:url' />
<meta content="#### Some verbose trashFor most nonlinear inverse problem, direct solution is not accessible easily, thus many people..." property='og:description' />
<meta content="article" property="og:type" />

<!-- - -->
<script type="text/javascript">
	var _gaq = _gaq || [];
	_gaq.push(['_setAccount', 'UA-19164221-4']);
	_gaq.push(['_trackPageview']);
	(function() {
		var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
		ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
		var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
	})();
</script>
<script>(function(d, s, id) {
	var js, fjs = d.getElementsByTagName(s)[0];
	if (d.getElementById(id)) return;
	js = d.createElement(s); js.id = id;
	js.src = "//connect.facebook.net/en_GB/all.js#xfbml=1&appId=604714799556697";
	fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>

  </head>
  <body>
    <header>
<a id="go-back-home" href="/users/yzhong"><img src="/users/yzhong/images/scribble.png" alt="scribble" width="53" height="59"></a>
<p>Welcome to Yimin's Homepage</p>
</header>

    <div id='container'>
      <div class="block">
  
    <a target="_top" class="main" href="/users/yzhong/cv">CV</a>
  
    <a target="_top" class="main" href="/users/yzhong/research">Research</a>
  
    <a target="_top" class="main" href="/users/yzhong/teach">Teach</a>
  
    <a target="_top" class="main" href="/users/yzhong/more">More</a>
  
    <a target="_top" class="main" href="/users/yzhong/blog">Blog</a>
  
    <a target="_blank" class="main" href="mailto:yzhong@math.utexas.edu">Email</a>
  
</div>

      <section class="paging">
  
    <div class="left">
      <a href="/users/yzhong/2017/07/23/jenkins-for-simulation/">
        â€¹
      </a>
    </div>
  
  
</section>

      <div class="content">
        <section class='post'>
          <h1 class="upcase">
            <div class='date'>25 Jul 2017</div>
            Bregman As Default?
          </h1>
          <h4 id="toc_0">Some verbose trash</h4>

<p>For most nonlinear inverse problem, direct solution is not accessible easily, thus many people chose an iterative optimization scheme.</p>

<p>Suppose forward model $\mathcal{M}: (\sigma, u_g, g)\to m$ passes unknown variable coefficient $\sigma\in \mathcal{E}$, unknown solution $u_g$ and known input $g\in\mathcal{G}$ to some observable measurement $m$, where $u$ satisfies solution model constraint $F(u_g, \sigma, g) = 0$. we usually use minimization scheme:
$$\min_{\sigma} J(\sigma, u_g) = \sum_{g\in\mathcal{G}} |\mathcal{M}(\sigma, u_g, g) - m|^q + \frac{\beta}{2}|\sigma|_{p}$$</p>

<p>values for $p,q$ are found everywhere, common choices for regularization is TV or $L_1, L_2$.</p>

<p>When $q=2$, adjoint method is often used to reduce computational cost, ignoring $g$ for each input,</p>

<p>$$\frac{\partial |\mathcal{M}(\sigma,u) - m|^2}{\partial \sigma} (\delta \sigma)=2( \frac{\partial \mathcal{M}}{\partial \sigma}(\delta \sigma))^t(\mathcal{M}(\sigma,u) - m)$$
and
$$\frac{\partial \mathcal{M}(\sigma, u)}{\partial \sigma}(\delta \sigma) = \mathcal{M}_{\sigma}\delta\sigma + \mathcal{M}_{u}\frac{\partial u}{\partial \sigma}(\delta \sigma)$$</p>

<p>we need to resolve $\frac{\partial u}{\partial \sigma}$ which is reduced from solution model that
$$F_u \frac{\partial u}{\partial \sigma}(\delta \sigma) + F_{\sigma}(\delta\sigma) = 0$$</p>

<p>so we have
$$\frac{\partial \mathcal{M}(\sigma, u)}{\partial \sigma}(\delta \sigma) = \mathcal{M}_{\sigma}\delta\sigma + \mathcal{M}_u F_u^{-1} F_{\sigma}(\delta\sigma)$$</p>

<p>The $F^{-1}_u$ is some solution operator, we take adjoint, then we only need solve
$$(F_{\sigma}(\delta\sigma))^t F_u^{-t} \mathcal{M}_u^t (\mathcal{M}(\sigma, u) - m)$$</p>

<p>Now, for each iteration, we need to evaluate operations, mostly matrix-vector multiplications.</p>

<p>$$\mathcal{M}_u^t(y), F_u^{-t}(y), F_{\sigma}(y), F^{-1}(y)$$</p>

<p>For linear operators, we have $F_u = F$, but $F_{\sigma}$ has to be calculated separately, for large system, $F^{-1}$ is nontrivial to update fast.</p>

<p>This is the unconstrained version. This version of numerical implementation has to calculate exact solutions to $F$ multiple times $O(1)$.</p>

<p>In order to quantify the cost, we consider following model of time cost.</p>

<ul>
<li>$t_{mv}$ is sparse matrix-vector multiplication time.</li>
<li>$t_{sv}$ is the inversion time.</li>
<li>$t_{pre}$ is precomputing time for <code>mv</code> or <code>sv</code>.</li>
<li>$t_{set}$ is total intrinsic setting time for all operators, which is minimal.</li>
</ul>

<p>Total time for each iteration will be: $t_{set} + t_{pre} + 2t_{sv} + (n+1)t_{mv}$. When the operators are sparse (local), then $t_{mv} = O(n)$, $t_{sv} = O(n)$, but mostly ill-conditioned, preconditioner is needed, total is $O(n^2)$. In this case, it is not optimal to use the low rank compression here due to high overhead in $t_{pre}$.</p>

<p>If $F$ is integral equation, then system is dense. $F_u^{-1}$ or $F^{-1}$ is not cheap to calculate in practice, iterative method might be utilized for such problems, in such case, low rank method can kick in.</p>

<p>Then we look at constrained version. Optimization problem is
$$\min_{\sigma, u_g} J(\sigma, u_g) = \sum_{g\in\mathcal{G}} |\mathcal{M}(\sigma, u_g, g) - m|^q + \frac{\beta}{2}|\sigma|_{p}$$
subject to
$$F(u_g, \sigma, g) = 0.$$</p>

<p>The Lagrangian multiplier method gives
$$\min_{\sigma, u_g, \lambda}L(\sigma, u_g, \lambda_g) =  J(\sigma, u_g) - \sum_g\lambda_g F_g$$</p>

<p>The KKT conditon says
$$J_{\sigma} = \sum_g \lambda_g F_{g,\sigma},\quad J_{u_g} = \sum_{g}\lambda_g F_{g, u_g}$$</p>

<p>To solve the problem, we use some penalty term in addition to get <code>AL</code> as
$$L_{aug}(\sigma, u_g, \lambda_g, \mu) = J(\sigma, u_g) - \sum_{g}\lambda_g F_g + \frac{\mu}{2}|F(u_g,\sigma, g)|^2$$</p>

<p>Then KKT condition implies at $k$-th iteration,<br>
$$J_{\sigma} -(\sum_g\lambda^k_g - \mu^k F)F_{g,\sigma} = 0 ,\quad J_{u_g} -(\sum_g\lambda^k_g - \mu^k F)F_{u_g,\sigma} = 0 $$</p>

<p>which implies that near optimal, we have
$$\lambda_g^{\ast} = \lambda^{k}_g - \mu^k F_g.$$
giving equivalent Bregman iteration as
$$\lambda_g^{k+1} = \lambda^{k}_g - \mu^k F_g.$$</p>

<h4 id="toc_1">Bregman is faster ?</h4>

<p>No matter what method, one problem is in common, we need to solve sub-problem of finding $(\sigma^k, u_g^k)$ each time.</p>

<p>In unconstrained case, $u_g$ must be solution of $F$. In Bregman, it is not. The problem is unconstrained, variables will increase to $O(n + N)$, where $n$ is unknowns of $\sigma$ and $N$ is unknowns of $u_g$.</p>

<p>Let&#39;s put everything into Bregman&#39;s frame, set $u = (\sigma, u_g)$ and $J(u)$ defined in previous part is convex in $u$ and penalty term is
$$H(u) = \frac{\mu}{2}|F(u, g)|^2$$</p>

<p>We are solving
$$\min_u {J(u) + H(u)}$$</p>

<p>with Bregman distance $D^p_J(u, v) = J(u) - J(v) - \langle p , u-v\rangle$,the iteration is given by</p>

<ul>
<li>$u^{k+1} = \arg\min_{u} D_J^{p^k}(u , u^k) + H(u)$</li>
<li>$p^{k+1} = p^k - \nabla H(u^{k+1})\in \partial J(u^{k+1})$</li>
<li>update $\mu$.</li>
</ul>

<p>So what is the complexity in each iteration? In first update, we solve a minimization problem by BFGS/Newton. This problem is not easier than original problem at all. But adding $\mu$ makes the system less ill-conditioned, so finding a solution needs less iterations, while total iteration number might be large.</p>

          <br />



        </section>
      </div>
      

      
        <div class="block">
  <div id="disqus_thread"></div>
  <script type="text/javascript">
      /* * * CONFIGURATION VARIABLES * * */
      var disqus_shortname = 'outverse';

      /* * * DON'T EDIT BELOW THIS LINE * * */
      (function() {
          var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
          dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
          (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      })();
  </script>
  <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a></noscript>
</div>

      
      <div class="block">
  
    <a target="_top" class="main" href="/users/yzhong/cv">CV</a>
  
    <a target="_top" class="main" href="/users/yzhong/research">Research</a>
  
    <a target="_top" class="main" href="/users/yzhong/teach">Teach</a>
  
    <a target="_top" class="main" href="/users/yzhong/more">More</a>
  
    <a target="_top" class="main" href="/users/yzhong/blog">Blog</a>
  
    <a target="_blank" class="main" href="mailto:yzhong@math.utexas.edu">Email</a>
  
</div>

    </div>
    <footer>
  <a href="http://www.ma.utexas.edu" class="muted">Dept. of Math@University of Texas at Austin</a>
  <br />
</footer>

  </body>
</html>
