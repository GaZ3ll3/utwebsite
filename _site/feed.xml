<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Welcome to Yimin's Homepage</title>
    <description>Academic homepage of Yimin</description>
    <link>http://www.ma.utexas.edu/users/yzhong</link>
    <atom:link href="http://www.ma.utexas.edu/users/yzhong/feed.xml" rel="self" type="application/rss+xml" />
    
      <item>
        <title>Simplified Spherical Harmonics</title>
        <description>&lt;p&gt;Simplified spherical harmonics $SP_n$ comes from infinite slab model, under strong scattering, one only needs to focus on azimuth angle scattering, and for the other direction of angle, it will integrate out.&lt;/p&gt;

&lt;p&gt;Another good property of $SP_n$ is the recursive property of Legendre polynomials combined with odd-even parity, gives a &lt;strong&gt;non-sparse&lt;/strong&gt; system.&lt;/p&gt;

&lt;p&gt;Take
$$\psi_i = (2i-1)\phi_{2i - 2} + (2i)\phi_{2i}$$&lt;/p&gt;

&lt;p&gt;$SP_7$ will give a matrix between $\psi$ and $\phi$, only with even terms of $\phi$.
$$
\begin{pmatrix}
1 &amp;amp; 2 &amp;amp; 0 &amp;amp; 0\
0 &amp;amp; 3 &amp;amp; 4 &amp;amp; 0\
0 &amp;amp; 0 &amp;amp; 5 &amp;amp; 6\
0 &amp;amp; 0 &amp;amp; 0 &amp;amp; 7
\end{pmatrix}\phi = \psi
$$
with a trivial inversion.  The differential operator system gives&lt;/p&gt;

&lt;p&gt;$$L_i \psi_i = \sum_i S_{ij} \psi_j + g_i$$&lt;/p&gt;

&lt;p&gt;where $L_i$ are second order differential operators and $S$ &lt;strong&gt;is&lt;/strong&gt; sparse. Under finite element method framework, we will arrive at a linear system that&lt;/p&gt;

&lt;p&gt;$$(\mathrm{diag}(L_i) - S )\psi = g$$&lt;/p&gt;

&lt;p&gt;But with integral equation,&lt;/p&gt;

&lt;p&gt;$$\psi_i = \sum_i A_{ij} \psi_j + f$$&lt;/p&gt;

&lt;p&gt;the operators $A_{ij}$ are evaluated separately and $A = (A_{ij})$ is &lt;strong&gt;not&lt;/strong&gt; sparse.&lt;/p&gt;

&lt;p&gt;These two methods have very similar last step, but they are quite different in many ways, in theory, differential equation form will work better because of lower computational cost. Unless there is a way to reduce the cost of integral equation&amp;#39;s cost.&lt;/p&gt;
</description>
        <pubDate>Thu, 10 Nov 2016 00:00:00 -0600</pubDate>
        <link>http://www.ma.utexas.edu/users/yzhong/2016/11/10/simplified-spherical-harmonics/</link>
        <guid isPermaLink="true">http://www.ma.utexas.edu/users/yzhong/2016/11/10/simplified-spherical-harmonics/</guid>
      </item>
    
      <item>
        <title>Time domain RTE</title>
        <description>&lt;p&gt;The time dependent radiative transport equation is stated as
$$
\begin{equation}
\begin{aligned}
&amp;amp;\frac{1}{c}\frac{\partial u}{\partial t} + \hat{s}\cdot \nabla u = \sigma(B(\nu, T) - u)\\
&amp;amp;C_{\nu}\frac{\partial T}{\partial t} = \int_{S^{d-1}}\int_0^{\infty} \sigma(u - B(\nu, T)) d\nu d\hat{s}
\end{aligned}
\end{equation}
$$
which describes the interaction of material and radiation. where $u(x, t, \hat{s},\nu)$ is radiation intensity, $T = T(x,t)$ is material temperature. $\sigma = \sigma(x, \nu, T)$ is opacity thickness, $C_{\nu}$ is heat capacity.
$$B(\nu, T) = \frac{2h}{c^3}\frac{\nu^3}{\exp(h\nu/k T) - 1}$$&lt;/p&gt;

&lt;p&gt;by using approximation, the equation can be rewritten as an easier one,
$$
\begin{equation}
\begin{aligned}
&amp;amp;\frac{1}{c}\frac{\partial u}{\partial t} + \hat{s}\cdot \nabla u + \sigma u = \frac{\sigma b}{|S^{d-1}|} acT^4\\
&amp;amp;C_{\nu}\frac{\partial T}{\partial t} = \int_{S^{d-1}}\int_0^{\infty} \sigma d\nu \int_{S^{d-1}} u \hat{s} - \sigma_p acT^4
\end{aligned}
\end{equation}
$$&lt;/p&gt;

&lt;p&gt;where $b$ is average of $B$, $\sigma_p$ is average of $\sigma b$.&lt;/p&gt;

&lt;p&gt;There is a way to decouple the equations, by taking $t$ as another spatial variable. $z = (x, t)$, we have
$$
\tilde{s}\cdot \nabla_z u + \sigma(z, \nu) u = H(z, \nu)
$$&lt;/p&gt;

&lt;p&gt;which is quite easy to come up with a solution for $\phi = \int_{S^{d-1}} u$. And insert into temperature equation.&lt;/p&gt;

&lt;p&gt;$$C_{\nu}\frac{\partial T}{\partial t} = \int_0^{\infty}\sigma d\nu \int_{S^{d-1}}\int_0^{\tau^{-}(z,\tilde{s})} \exp(-\int_0^p\sigma(z-\mu\tilde{s})d\mu) H(z - p\tilde{s}) dp d\tilde{s} - \sigma_p ac T^4$$&lt;/p&gt;

&lt;p&gt;And solving this can apply some fast algorithm like &lt;code&gt;treecode&lt;/code&gt; or &lt;code&gt;FMM&lt;/code&gt; as we did before, forward Euler scheme will generate $O(\Delta x)$ error.&lt;/p&gt;
</description>
        <pubDate>Mon, 19 Sep 2016 00:00:00 -0500</pubDate>
        <link>http://www.ma.utexas.edu/users/yzhong/2016/09/19/time-domain-RTE/</link>
        <guid isPermaLink="true">http://www.ma.utexas.edu/users/yzhong/2016/09/19/time-domain-RTE/</guid>
      </item>
    
      <item>
        <title>Differential Equation VS. FMM</title>
        <description>&lt;p&gt;After a long time of thinking, I would say fast multiple method is not a good method for solving differential equation, though it is a great algorithm.&lt;/p&gt;

&lt;h4 id=&quot;toc_0&quot;&gt;interpolation vs. extrapolation&lt;/h4&gt;

&lt;p&gt;Finite difference method on a structured grid, approximating the differential operator using stencil, will generate a sparse system, which generally gives $\mathcal{O}(N)$ complexity, the constant depends on the wanted precision and order of equation.&lt;/p&gt;

&lt;p&gt;The error analysis usually gives $\mathcal{O}(h^s)$, decreasing w.r.t $h$ the grid size.&lt;/p&gt;

&lt;p&gt;FMM, in someway we can obtain the Green function, the solution is integral form, the error comes from two parts.&lt;/p&gt;

&lt;p&gt;The first is discretization, depending on $h$. The second is from FMM algorithm itself, depending on its parameters, could be arbitrarily small, but will be dominated by the first one easily, a good rule is to select parameters to be comparable to the discretization error.&lt;/p&gt;

&lt;p&gt;Well, the discretization error is terrible for FMM, to make the precision high enough, interpolation is very important, we need to import more points on the smallest resolution to get a high order quadrature rule, increasing the computing cost by a linear constant. The case is: this constant is as the same level as FDM (which uses extrapolation).&lt;/p&gt;

&lt;h4 id=&quot;toc_1&quot;&gt;when to use&lt;/h4&gt;

&lt;p&gt;I think, the only case to use FMM on equation, is only good on integral equation only, no explicit differential equation is available. Unless FMM can reduce a lot of computation cost, otherwise, there is no need to use.&lt;/p&gt;
</description>
        <pubDate>Sun, 04 Sep 2016 00:00:00 -0500</pubDate>
        <link>http://www.ma.utexas.edu/users/yzhong/2016/09/04/differential-equation-vs-fmm/</link>
        <guid isPermaLink="true">http://www.ma.utexas.edu/users/yzhong/2016/09/04/differential-equation-vs-fmm/</guid>
      </item>
    
      <item>
        <title>Thoughts on Fast Multipole III</title>
        <description>&lt;p&gt;Continue with last post. Consider the pseudo-differential elliptic operator $P = \sum_{|\alpha|\le 2m} c_{\alpha}(x) D^{\alpha}$, if we have $P u(x) = f(x)$, with Dirichlet boundary condition $u^{\alpha} = 0$ for $|\alpha|\le m-1$.&lt;/p&gt;

&lt;p&gt;$$\int_{\Omega}(P^{\ast}v(x, y))u(x) -  (Pu(x)) v(x, y) dx   = \sum_{\beta}\int_{\partial\Omega}\psi_{\beta}(x) v^{\beta}(x, y) dx$$&lt;/p&gt;

&lt;p&gt;Here consider Green function $P^{\ast}v(x, y) = \delta_y(x)$, which is $P v(y, x) = \delta_y(x)$. If we say $K(x, y)$ is Green function of $P$, then we have to replace $x$ and $y$ in $v$, thus $K(x, y) = v(y, x)$.&lt;/p&gt;

&lt;p&gt;$$u(y) - \int_{\Omega}  f(x)K(y, x)dx = \sum_{\beta} \int_{\partial\Omega}\psi_{\beta}(x) K^{\beta}(y, x) dx$$&lt;/p&gt;

&lt;p&gt;Now come back to our previous exterior problem, if $f = 0$ in $\Omega^{c}$, then for $y\in\Omega$, here $\Omega$ could be internal domain or external domain.&lt;/p&gt;

&lt;p&gt;$$u(y) =\sum_{|\beta|\le m - 1}\int_{\partial\Omega}\psi_{\beta}(x) K^{\beta}(y, x) dx$$&lt;/p&gt;

&lt;p&gt;In 2D, there are $C_{m+1}^2$ terms in this summation, with discretization, and merge weights into $\psi$.&lt;/p&gt;

&lt;p&gt;$$u(y_j) = \sum_{\beta} \sum_{k=1}^p \psi_{\beta}(x_k) K^{\beta}(x_k, y_j) $$&lt;/p&gt;

&lt;p&gt;There are $pC_{m+1}^2$ unknowns for this problem. Just one surface is enough. This can be seen as an extension of &lt;code&gt;KIFMM&lt;/code&gt; method.&lt;/p&gt;

&lt;h3 id=&quot;toc_0&quot;&gt;Numerical concerns&lt;/h3&gt;

&lt;p&gt;The summation over $\partial\Omega$ requires too many points (unknowns) to find out. Here we can simulate  $K^{\beta}(x_k, y_j)$ by taking finite difference to approximate the derivatives. Then we only need $m$ surfaces to find out all $K^{\beta}(x, \cdot)$, each surfaces we can place equally spaced $p$ points.&lt;/p&gt;

&lt;h3 id=&quot;toc_1&quot;&gt;Infinite order case&lt;/h3&gt;

&lt;p&gt;It seems to me that given all points inside a annulus will be enough for this.&lt;/p&gt;

&lt;h3 id=&quot;toc_2&quot;&gt;Failure for numerics&lt;/h3&gt;

&lt;p&gt;Just for a update. In numerical world, finite difference is rather a really bad idea to approximate derivatives, esp. those high order terms. Thus &lt;code&gt;KIFMM&lt;/code&gt; is an effective fast &lt;em&gt;low&lt;/em&gt; order PDE solver.&lt;/p&gt;
</description>
        <pubDate>Fri, 19 Aug 2016 00:00:00 -0500</pubDate>
        <link>http://www.ma.utexas.edu/users/yzhong/2016/08/19/thoughts-on-fast-multipole-iii/</link>
        <guid isPermaLink="true">http://www.ma.utexas.edu/users/yzhong/2016/08/19/thoughts-on-fast-multipole-iii/</guid>
      </item>
    
      <item>
        <title>Thoughts on Fast Multipole II</title>
        <description>&lt;p&gt;In last post, I sort of believe that &lt;code&gt;KIFMM&lt;/code&gt; was limited to a small portion of PDE, especially for second order elliptic equations, while the deeper idea is not the same thing at all.&lt;/p&gt;

&lt;h3 id=&quot;toc_0&quot;&gt;Equivalence of information&lt;/h3&gt;

&lt;p&gt;I realized that there is something called &lt;code&gt;Equivalence of information&lt;/code&gt; here, for example, Laplacian $\Delta u = 0$ made solution depending only information on boundary, as we called boundary value problems.  Then we can define the equivalence class of equation $P u = 0$ that associated with pseudo-differential operator $P$.&lt;/p&gt;

&lt;p&gt;In theory, even higher ordered elliptic equation&lt;/p&gt;

&lt;p&gt;$$P(x, D) u =  \sum_{|\alpha| \le 2m} c_{\alpha} D^{\alpha} u = 0$$&lt;/p&gt;

&lt;p&gt;we can see that for this equation, classical results could apply easily, and we consider the weak formulation, if vector-function $\tilde{g} = (g_{\alpha})_{|\alpha|\le m-1}$,  which satisfies
$$|\tilde{g}| = \sum_{\alpha} |g_{\alpha}| $$
is finite, we say $\tilde{g} \in W^{m-1}(\partial\Omega)$. We are looking for $u\in W^{2m}(\Omega)\cap W^{m-1}(\overline{\Omega})$ such that  $Pu = 0$ and $D^{\alpha} u|_{\partial\Omega} = g_{\alpha}$.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;For any bounded domain $\Omega$, there is unique weak solution to the Dirichlet problem $P u = 0$. When boundary is smooth enough, the weak solution is also classical solution.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;On the other hand, the exterior problem also has unique solution for the same Dirichlet boundary conditions.&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;If $Pu = 0$, for any given measure $\nu^{\alpha}\in\Omega$, there exists $\mu^{\alpha}\in \partial\Omega$ that
$$\sum_{|\alpha|\le m-1} \int (D^{\alpha}u) d\mu^{\alpha} = \sum_{|\alpha|\le m -1} \int (D^{\alpha} u) d\nu^{\alpha}$$&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The proof should be found somewhere in &lt;code&gt;ADN (Agmon, Douglis, Nirenberg)&lt;/code&gt;, uniqueness could be concluded from something similar of Lax-Milgram. That also reveals the fact that this operator $P$ has equivalence class $\Omega\sim (\partial\Omega)^{m}$. Since we can use finite difference method to approximate $D^{\alpha} u$ on $\partial \Omega$, by giving $u$ at $\partial\Omega + t_i\mathbf{n}$ surfaces, where $t_0, \cdots, t_{m-1}\in (0,\epsilon)$. Now our problem is how to generate those surfaces/or small domains for equivalence potential.&lt;/p&gt;

&lt;h3 id=&quot;toc_1&quot;&gt;Equivalent cluster of surfaces&lt;/h3&gt;

&lt;p&gt;Define cluster of surfaces $C(t_i),i=0,\cdots, m-1$, where $C(t_i) = {x + t_i \mathbf{n}, x\in \partial\Omega}$. We also consider the solutions on each surfaces $C_i = C(t_i)$ as $u_i$.&lt;/p&gt;

&lt;p&gt;Then $D^{\alpha} u$ can be computed through finite difference. Especially, on square surface, this is quite straightforward to compute each derivatives.&lt;/p&gt;

&lt;h3 id=&quot;toc_2&quot;&gt;Exterior to Interior problem&lt;/h3&gt;

&lt;p&gt;Consider free space Green function for internal source $f$, the whole space solution is
$$u(x) = \int_{\Omega} K(x, y) f(y) dy$$
and here we are looking for $\Lambda_{\alpha}$ such that $x\in \Omega^{c}$,
$$u(x) = \sum_{|\alpha|\le m - 1} \int_{\partial\Omega} \Lambda_{\alpha}(x, y) \underline{D^{\alpha} u(y)}dy$$&lt;/p&gt;

&lt;h3 id=&quot;toc_3&quot;&gt;Interior to Exterior problem&lt;/h3&gt;

&lt;p&gt;The exterior problem will be the same, except the source $f$ lives outside of the domain $\Omega$.&lt;/p&gt;
</description>
        <pubDate>Thu, 18 Aug 2016 00:00:00 -0500</pubDate>
        <link>http://www.ma.utexas.edu/users/yzhong/2016/08/18/thoughts-on-fast-multipole-II/</link>
        <guid isPermaLink="true">http://www.ma.utexas.edu/users/yzhong/2016/08/18/thoughts-on-fast-multipole-II/</guid>
      </item>
    
      <item>
        <title>Thoughts on Fast Multipole</title>
        <description>&lt;p&gt;We are most interested in those kernel independent methods, and so far, we are aware of two mainstream methods, one is &lt;code&gt;KIFMM&lt;/code&gt;, the other is &lt;code&gt;BBFMM&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;They have very similar structure(upward pass, downward pass) of algorithm and exact the same data interaction, we call these common steps &lt;code&gt;M2M&lt;/code&gt;, &lt;code&gt;M2L&lt;/code&gt;, &lt;code&gt;L2L&lt;/code&gt;, by building a &lt;code&gt;kd-tree&lt;/code&gt;, with each leaf node containing at least $s$ particles. The brief algorithm is described as&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;python language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;c&quot;&gt;# build tree(partly) involves S2M, M2M two parts.&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;upwardPass&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;c&quot;&gt;# postorder traversal&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;particles&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threshold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# it is at leaf&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;S2M&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# not leaf&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;divide&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;xrange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;upwardPass&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;child&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;M2M&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;python language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;c&quot;&gt;# downPass involves M2L, L2L.&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;downPass&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;c&quot;&gt;# preorder&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;isLeaf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;L2L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# U List&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;L2P&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# put current data into correct spots&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;processData&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# V List&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;M2L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;# preorder traversal&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;xrange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;downPass&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;node&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;child&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The algorithm is trivial with understanding of the information flow, however, we are particular interested in the core idea.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;KIFMM&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;It bases on potential theory in harmonic analysis, or simply Green&amp;#39;s formula for second order operator like Laplacian. Second order PDE always has unique solution for exterior and interior boundary value problem, which means, the kernel must obey harmonic property, inside information must be equivalent(can transform to each other) to information on surface.&lt;/p&gt;

&lt;p&gt;This makes the algorithm very effective if the kernel is fundmental solution of second order PDE, because, using a few points on surface will total be equivalent to all nodes inside the grid.&lt;/p&gt;

&lt;p&gt;However, the limitation is also obvious, it can only work under the second order PDE, because the equation must have the potential property, that outside information can be calculated through following boundary integral, since the source is inside $\Omega$, it is a homogeneous exterior boundary value problem, solution should be something like&lt;/p&gt;

&lt;p&gt;$$u(x) = \int_{\partial\Omega} K(x, y) \psi(y)$$&lt;/p&gt;

&lt;p&gt;If the kernel does not fit the potential theory framework, this method does not work anymore, surface/boundary value cannot be used for the evaluation of the solution merely.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;BBFMM&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;This is method is something general, but requires more time on solution for special problems, since interpolation methods always need redundant interior data, this method actually is doing expansion of the kernel into small decoupling products.&lt;/p&gt;

&lt;p&gt;$$K(x, y) \sim \sum_{k=1}^N c_k S_k(x)T_k(y)$$&lt;/p&gt;

&lt;p&gt;Currently, there are some polynomial based $S_k, T_k$ such as Chebyshev and Lagrange, providing cut-off residue as higher ordered terms.&lt;/p&gt;

&lt;p&gt;We are more interested in selecting appropriate basis $S$ and $T$ such that&lt;/p&gt;

&lt;p&gt;$$\min |K(x, y) - \sum_{k=1}^N c_k S_k(x)T_k(y)|_{L^p(\Omega\times \Omega)}$$&lt;/p&gt;

&lt;p&gt;since in discretized model, this turns out to be&lt;/p&gt;

&lt;p&gt;$$\min\max_i | \sum_j K(x_i, y_j)\phi_j -\sum_{k=1}^N c_k S_k(x_i)\sum_j T_k(y_j)\phi_j| $$&lt;/p&gt;

&lt;p&gt;we observe that once the functions are found, the cost will be $\mathcal{O}(N n)$. It is quite straightforward to see Fourier transform is an example, but only good for fluctuation kernel, for smooth case, polynomial could be good approximation with good performance in accuracy. Thus if we are facing some unknown kernel or something other than second order PDE, &lt;code&gt;BBFMM&lt;/code&gt; is somewhat a first choice for the first try.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Tue, 16 Aug 2016 00:00:00 -0500</pubDate>
        <link>http://www.ma.utexas.edu/users/yzhong/2016/08/16/thoughts-on-fast-multipole/</link>
        <guid isPermaLink="true">http://www.ma.utexas.edu/users/yzhong/2016/08/16/thoughts-on-fast-multipole/</guid>
      </item>
    
      <item>
        <title>More on Transport</title>
        <description>&lt;p&gt;The radiative transfer equation involves several parameters, $\mu_t$,
$\mu_s$ be the attenuation(transport) and scattering coefficient
respectively. $K(\hat{\mathbf{s}}, \hat{\mathbf{s}}&amp;#39;)$ is the phase
function describing the probability of scattering from
$\hat{\mathbf{s}}$ to $\hat{\mathbf{s}}&amp;#39;$.&lt;/p&gt;

&lt;p&gt;$$\hat{\mathbf{s}}\cdot \nabla u(\mathbf{r}, \hat{\mathbf{s}}) + \mu_t u(\mathbf{r}, \hat{\mathbf{s}}) = \mu_s \frac{1}{\mathrm{Vol}(\mathbb{S}^{d-1})}\int_{\mathbb{S}^{d-1}} K(\hat{\mathbf{s}}\cdot \hat{\mathbf{s}}&amp;#39;) u(\mathbf{r}, \hat{\mathbf{s}}&amp;#39;) d\hat{\mathbf{s}}&amp;#39; + q$$&lt;/p&gt;

&lt;p&gt;When the phase function is isotropic, we are aware that FMM based
algorithm would be a good approximation to the solution. Here we try to
develop more application cases.&lt;/p&gt;

&lt;h2 id=&quot;toc_0&quot;&gt;Isotropic $\delta$-Eddington approximation&lt;/h2&gt;

&lt;p&gt;In 3D, the phase function is selected as&lt;/p&gt;

&lt;p&gt;$$K(\cos\theta) = 2f\delta(1 - \cos\theta) + (1-f)(1 + 3g&amp;#39;\cos\theta)$$&lt;/p&gt;

&lt;p&gt;where $f = g^2, g&amp;#39; = g/(1+g)$ are constant parameters and
$\cos\theta = \hat{\mathbf{s}}\cdot \hat{\mathbf{s}}&amp;#39;$. Then the RTE
will be reduced to&lt;/p&gt;

&lt;p&gt;$$\hat{\mathbf{s}}\cdot \nabla u(\mathbf{r}, \hat{\mathbf{s}}) + \mu_t&amp;#39;u(\mathbf{r}, \hat{\mathbf{s}}) = \mu_s&amp;#39;\frac{1}{\mathrm{Vol}(\mathbb{S}^{d-1})}\int_{\mathbb{S}^2}(1 + 3g&amp;#39; \hat{\mathbf{s}}\cdot \hat{\mathbf{s}}&amp;#39;) u(\mathbf{r}, \hat{\mathbf{s}}&amp;#39;) d\hat{\mathbf{s}}&amp;#39; + q$$&lt;/p&gt;

&lt;p&gt;where $\mu_s&amp;#39; = (1- f)\mu_s$ and $\mu_t&amp;#39; = \mu_a + \mu_s&amp;#39;$. If $g&amp;#39; = 0$,
we will again land on our original FMM settings.&lt;/p&gt;

&lt;h2 id=&quot;toc_1&quot;&gt;Anisotrpic $\delta$-Eddington approximation&lt;/h2&gt;

&lt;p&gt;Here we consider more general case $g&amp;#39;\neq 0$, to simplify our work, we
assume the domain $\Omega\subset \mathbb{R}^2$, where $\delta$-Eddington
approximation should be similar. We consider the equation with ,&lt;/p&gt;

&lt;p&gt;$$\hat{\mathbf{s}}\cdot \nabla u(\mathbf{r}, \hat{\mathbf{s}}) + \mu_t u(\mathbf{r}, \hat{\mathbf{s}}) = \mu_s \frac{1}{\mathrm{Vol}(\mathbb{S}^{d-1})}\int_{\mathbb{S}^2}(1 + \kappa\hat{\mathbf{s}}\cdot \hat{\mathbf{s}}&amp;#39;) u(\mathbf{r}, \hat{\mathbf{s}}&amp;#39;) d\hat{\mathbf{s}}&amp;#39; + q$$&lt;/p&gt;

&lt;p&gt;where $\kappa$ is an appropriate constant. In 2D, we can substitute
$\hat{\mathbf{s}}$ with $\theta$. And
$\hat{\mathbf{s}}\cdot \hat{\mathbf{s}}&amp;#39; = \cos\theta \cos\theta&amp;#39; + \sin\theta\sin\theta&amp;#39;$.
Then&lt;/p&gt;

&lt;p&gt;$$
    u(\mathbf{r}, \theta) = \int_0^{\tau_{-}(\mathbf{r}, \theta)} E(\mathbf{r}, \mathbf{y})\Big( \mu_s(\mathbf{y})\left(U(\mathbf{y}) + \kappa C(\mathbf{y})\cos\theta  + \kappa S(\mathbf{y})\sin\theta \right) + q(\mathbf{y})\Big) dt
$$&lt;/p&gt;

&lt;p&gt;where $y = \mathbf{r}- t\hat{\mathbf{s}}$, $E(\mathbf{r},\mathbf{y})$ is
the line integral, and&lt;/p&gt;

&lt;p&gt;$$\begin{aligned}
    U(\mathbf{r}) &amp;amp;= \frac{1}{2\pi}\int_0^{2\pi} u(\mathbf{r}, \theta) d\theta\\
    C(\mathbf{r}) &amp;amp;=  \frac{1}{2\pi}\int_0^{2\pi} \cos\theta u(\mathbf{r}, \theta) d\theta\\
    S(\mathbf{r}) &amp;amp;=  \frac{1}{2\pi}\int_0^{2\pi} \sin\theta u(\mathbf{r}, \theta) d\theta
    \end{aligned}
$$&lt;/p&gt;

&lt;p&gt;Then we integrate over $\theta \in \mathbb{S}^1$.&lt;/p&gt;

&lt;p&gt;$$U(\mathbf{r}) =  \frac{1}{2\pi}\int_0^{2\pi}  \int_0^{\tau_{-}(\mathbf{r}, \theta)} E(\mathbf{r}, \mathbf{y})\Big( \mu_s(\mathbf{y})\left(U(\mathbf{y}) + \kappa C(\mathbf{y})\cos\theta  + \kappa S(\mathbf{y})\sin\theta \right) + q(\mathbf{y})\Big) dt$$&lt;/p&gt;

&lt;p&gt;change from polar coordinate to Cartesian, also we know that&lt;/p&gt;

&lt;p&gt;$$(\cos\theta, \sin\theta) = \frac{\mathbf{r}- \mathbf{y}}{|\mathbf{r}- \mathbf{y}|}$$&lt;/p&gt;

&lt;p&gt;then&lt;/p&gt;

&lt;p&gt;$$\begin{aligned}
    U(\mathbf{r}) &amp;amp;= \int_{\mathbf{y}\in \Omega} \frac{1}{2\pi} \frac{E(\mathbf{r}, \mathbf{y})}{|\mathbf{r}- \mathbf{y}|} \Big(\mu_s(\mathbf{y}) U(\mathbf{y}) + q(\mathbf{y})\Big)d\mathbf{y}\\
    &amp;amp;+ \int_{y\in\Omega} \frac{\kappa}{2\pi} \frac{E(\mathbf{r}, \mathbf{y}) (\mathbf{r}_x - \ \mathbf{y}_x)}{|\mathbf{r}- \mathbf{y}|^2}\mu_s(\mathbf{y}) C(\mathbf{y}) d\mathbf{y}\\
    &amp;amp;+ \int_{y\in\Omega} \frac{\kappa}{2\pi} \frac{E(\mathbf{r}, \mathbf{y}) (\mathbf{r}_y - \ \mathbf{y}_y)}{|\mathbf{r}- \mathbf{y}|^2}\mu_s(\mathbf{y}) S(\mathbf{y}) d\mathbf{y}\end{aligned}
$$&lt;/p&gt;

&lt;p&gt;In the same way, we also have&lt;/p&gt;

&lt;p&gt;$$\begin{aligned}
    C(\mathbf{r}) &amp;amp;= \int_{\mathbf{y}\in \Omega} \frac{1}{2\pi} \frac{E(\mathbf{r}, \mathbf{y})(\mathbf{r}_x - \mathbf{y}_x)}{|\mathbf{r}- \mathbf{y}|^2} \Big(\mu_s(\mathbf{y}) U(\mathbf{y}) + q(\mathbf{y})\Big)d\mathbf{y}\\
    &amp;amp;+ \int_{y\in\Omega} \frac{\kappa}{2\pi} \frac{E(\mathbf{r}, \mathbf{y}) (\mathbf{r}_x - \ \mathbf{y}_x)^2}{|\mathbf{r}- \mathbf{y}|^3}\mu_s(\mathbf{y}) C(\mathbf{y}) d\mathbf{y}\\
    &amp;amp;+ \int_{y\in\Omega} \frac{\kappa}{2\pi} \frac{E(\mathbf{r}, \mathbf{y}) (\mathbf{r}_x - \ \mathbf{y}_x)(\mathbf{r}_y - \ \mathbf{y}_y)}{|\mathbf{r}- \mathbf{y}|^3}\mu_s(\mathbf{y}) S(\mathbf{y}) d\mathbf{y}\end{aligned}
$$&lt;/p&gt;

&lt;p&gt;$$\begin{aligned}
    S(\mathbf{r}) &amp;amp;= \int_{\mathbf{y}\in \Omega} \frac{1}{2\pi} \frac{E(\mathbf{r}, \mathbf{y})(\mathbf{r}_y - \mathbf{y}_y)}{|\mathbf{r}- \mathbf{y}|^2} \Big(\mu_s(\mathbf{y}) U(\mathbf{y}) + q(\mathbf{y})\Big) d\mathbf{y}\\
    &amp;amp;+ \int_{y\in\Omega} \frac{\kappa}{2\pi} \frac{E(\mathbf{r}, \mathbf{y}) (\mathbf{r}_x - \ \mathbf{y}_x)(\mathbf{r}_y - \mathbf{y}_y)}{|\mathbf{r}- \mathbf{y}|^3}\mu_s(\mathbf{y}) C(\mathbf{y}) d\mathbf{y}\\
    &amp;amp;+ \int_{y\in\Omega} \frac{\kappa}{2\pi} \frac{E(\mathbf{r}, \mathbf{y}) (\mathbf{r}_y - \ \mathbf{y}_y)^2}{|\mathbf{r}- \mathbf{y}|^3}\mu_s(\mathbf{y}) S(\mathbf{y}) d\mathbf{y}\end{aligned}
$$&lt;/p&gt;

&lt;p&gt;which is a system of first kind integrals, let
$\Psi(\mathbf{r}) =   \begin{pmatrix}
    U(\mathbf{r})\\
    C(\mathbf{r})\\
    S(\mathbf{r})
    \end{pmatrix}$ and $Q(\mathbf{r}) =\begin{pmatrix}
    q(\mathbf{r})\\
    0\\
    0
    \end{pmatrix}$, then&lt;/p&gt;

&lt;p&gt;$$\Psi(\mathbf{r}) =
    \int_{y\in \Omega} \mathcal{K} (\mathbf{r}, \mathbf{y})\Big(\mu_s(\mathbf{y})\Psi(\mathbf{y}) + Q(\mathbf{y})\Big)
    d\mathbf{y}= K(\mu_s\Psi + Q
)$$&lt;/p&gt;

&lt;p&gt;It is obvious that solving $\Psi$ will automatically give solution
$u(\mathbf{r}, \theta)$ from .&lt;/p&gt;

&lt;p&gt;$$\Psi(\mathbf{r}) = \frac{1}{\mu_s} (I - \mu_sK )^{-1}(\mu_s K Q)$$&lt;/p&gt;

&lt;h2 id=&quot;toc_2&quot;&gt;Algorithm complexity&lt;/h2&gt;

&lt;p&gt;From above system, there are six kernels ($\mathcal{K}$ is symmetric) to
be calculated, also $\kappa K_{UU} = K_{CC} + K_{SS}$ can reduce the
evaluation complexity. Unlike our previous algorithm for isotropic phase
function, instead of caching all matrices for interaction (M2L) only, we
also will cache variables $E(\mathbf{r}, \mathbf{y})$ in order to
accelerate other kernels building process by re-using them, the time
complexity in caching the kernels will be $\mathcal{O}(nN_p)$. We solve
the linear system by Krylov subspace methods such as GMRES or MINRES, if
there are $l$ iterations, then the time cost is $\mathcal{O}(l^2 nN_p)$.&lt;/p&gt;

&lt;h2 id=&quot;toc_3&quot;&gt;Possible pre-conditioner for the system&lt;/h2&gt;

&lt;p&gt;In FMM, we have to evaluate the self-contribution on each grid, however,
we can easily observe that off-diagonal kernels in $K$ should produce
zero for self-contributions, and integrand will drop fast for further
points, thus we may approximate $K$ using its diagonal operators.&lt;/p&gt;

&lt;h2 id=&quot;toc_4&quot;&gt;Possible anisotropic source&lt;/h2&gt;

&lt;p&gt;Currently we cannot handle anisotropic source term
$q(\mathbf{r}, \hat{\mathbf{s}})$ unless we know exact explicit form, since the coupling between
$\mathbf{r}$ and $\hat{\mathbf{s}}$ could involve higher ordered terms
(in Legendre polynomial sense). In this very case, first order
approximation, we could assume
$q(\mathbf{r}, \theta) \sim q_0(\mathbf{r}) + \cos\theta q_c(\mathbf{r}) + \sin\theta q_s(\mathbf{r})$
without hurting the analysis and algorithm too much.&lt;/p&gt;

&lt;h2 id=&quot;toc_5&quot;&gt;Error analysis&lt;/h2&gt;

&lt;p&gt;Similar to previous report, the error of approximation by FMM is bounded
by $-C l \log (l) + \varepsilon_{FMM}$, when $l\to 0^{+}$.&lt;/p&gt;

&lt;h2 id=&quot;toc_6&quot;&gt;More general case&lt;/h2&gt;

&lt;p&gt;Consider the phase function $K(\hat{\mathbf{s}}\cdot \hat{\mathbf{s}}&amp;#39;)$
expansion in terms of $\hat{\mathbf{s}}\cdot \hat{\mathbf{s}}&amp;#39;$, with
Legendre polynomials for 3D or Chebyshev polynomial for 2D. Then similar
argument will bring us to a large linear system which requires very
intense evaluations of FMM kernels.&lt;/p&gt;
</description>
        <pubDate>Tue, 02 Aug 2016 00:00:00 -0500</pubDate>
        <link>http://www.ma.utexas.edu/users/yzhong/2016/08/02/more-on-transport/</link>
        <guid isPermaLink="true">http://www.ma.utexas.edu/users/yzhong/2016/08/02/more-on-transport/</guid>
      </item>
    
      <item>
        <title>Accelerated Transport</title>
        <description>&lt;p&gt;As I am concerned, all solvers without approximating with simply diffusion models must suffer from a very huge time cost in solutions. Including $P_N$, Monte Carlo, finite volume/element approaches in discrete ordinate method. The reason that diffusion model is plausible in many cases is the scattering effect is so strong, the particles movement is very similar as heat transfer in macroscopic scale. A very interesting thing here is, people were using DSA method for accelerate the transport solution by damping the error with diffusion solver first as a pre-conditioner, then it will be fast for transport solver to get the rest things done.&lt;/p&gt;

&lt;p&gt;Without a high priority in accuracy, the transport equation might be solved in a coarse way in every sense, it seems that without hurting the result, we can modify the transport model a little to achieve some boost in speed.&lt;/p&gt;

&lt;p&gt;$$ -\delta \Delta u + v\cdot \nabla u(x, v) + \sigma_t u = \sigma_s \frac{1}{\mathrm{Vol}(V)} \int_{V} u(x, v) dv +  q $$&lt;/p&gt;

&lt;p&gt;Now the equation will converge faster in each iteration, because we enhanced the first order approximation, which plays an important role in iterating.&lt;/p&gt;

&lt;p&gt;It seems this does not work well under the integration form since it produces differential-integral equation, which makes thing worse. Under other framework like discrete ordinate method, this method is better because Laplacian is easy to handle under Galerkin sense.&lt;/p&gt;
</description>
        <pubDate>Wed, 27 Jul 2016 00:00:00 -0500</pubDate>
        <link>http://www.ma.utexas.edu/users/yzhong/2016/07/27/accelerated-transport/</link>
        <guid isPermaLink="true">http://www.ma.utexas.edu/users/yzhong/2016/07/27/accelerated-transport/</guid>
      </item>
    
      <item>
        <title>Monte Carlo Transport</title>
        <description>&lt;p&gt;Radiative transport equation has multiple ways to solve, here I prefer to talk about one efficient way using MC.&lt;/p&gt;

&lt;p&gt;MC simulation will try to emit a huge number of particles and track each particle&amp;#39;s life cycle. We are particularly interested in intensity of the solution which is the angular integral of solution at each point. This will save a lot of time in simulating. As we know, the error related to MC is proportional to $\frac{1}{\sqrt{N}}$, where $N$ is the particles emitted at each point.&lt;/p&gt;

&lt;p&gt;We select an easier case to handle here,&lt;/p&gt;

&lt;p&gt;$$v \cdot \nabla u(x, v) + \sigma_t u = \sigma_s \frac{1}{\mathrm{Vol}(V)}\int_V u + q$$&lt;/p&gt;

&lt;p&gt;where $\sigma_t = \sigma_a + \sigma_s$, and coefficients are all positive constants. To put the model into numerical framework, we discretize the domain $[0,1]^2$ into small squares for convenience. Suppose we have mesh as $L \times L$, $L$ represents the number of boxes along one side.&lt;/p&gt;

&lt;p&gt;Following is the pseudo-code.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;python language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;location&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;domain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
  &lt;span class=&quot;n&quot;&gt;spawn&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;particles&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;particle&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;the&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;carries&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;energy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initially&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;has&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;finished&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;traveling&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;travel&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;along&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;its&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;direction&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;&lt;/span&gt;
      &lt;span class=&quot;n&quot;&gt;illuminate&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39; with its energy&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;going&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;be&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;absorbed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loop&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;since&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dead&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
      &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;change&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;its&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;direction&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;to&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;another&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;one&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The most time-costing part is random number generating. We can do this very quickly if we know the distribution and sample the distribution intentionally, which works perfectly under our case.&lt;/p&gt;

&lt;p&gt;The distance traveled is $-\log(\xi)/\sigma_t$, where $\xi\in U[0,1]$. The performance is good if there is not a large $N$ or $\sigma_s$ is not too large, we should have a quick stop for one run. For other cases, it will take a long time for sure.&lt;/p&gt;

&lt;p&gt;For parallel computing in this case, it will be better to run simulation distributed, using the MapReduce framework.&lt;/p&gt;

&lt;p&gt;One thing needs to point out is the discretized case, if we try to approximate the solution in $C^0$ sense, the error will not just first order, it will be worse than first order. Even if the coefficients are constants.&lt;/p&gt;
</description>
        <pubDate>Sat, 23 Jul 2016 00:00:00 -0500</pubDate>
        <link>http://www.ma.utexas.edu/users/yzhong/2016/07/23/monte-carlo-transport/</link>
        <guid isPermaLink="true">http://www.ma.utexas.edu/users/yzhong/2016/07/23/monte-carlo-transport/</guid>
      </item>
    
      <item>
        <title>Iterative regularization method</title>
        <description>&lt;h2 id=&quot;toc_0&quot;&gt;Regularization method&lt;/h2&gt;

&lt;p&gt;Consider non-linear problem $F(x) = y$, when $y$ is noised as $y^{\delta}$, such that $|y - y_{\delta}| \le \delta$, we know that ill-posed problem may not have a continuous inversion, and regularization methods are used to generate stable approximation of the solutions, especially when $\delta \to 0$, the approximation will converge to identification.&lt;/p&gt;

&lt;p&gt;$$ x_{\alpha}^{\delta} = \arg\min_{x} |F(x) - y^{\delta}|^2 + \alpha |x - x_0|^2 $$&lt;/p&gt;

&lt;p&gt;as I wrote before, this Tikhonov regularization is equivalent to maximum likelihood method, with prior information added. Under mild assumption, convergence rates results have been shown that if&lt;/p&gt;

&lt;p&gt;$$ \tilde{x} - x_0 = (F&amp;#39;(\tilde{x})^{\ast}F&amp;#39;(\tilde{x}))^{\mu})v  $$&lt;/p&gt;

&lt;p&gt;where $\mu \in (1/2, 1)$ and $|v|$ small enough, we have convergence&lt;/p&gt;

&lt;p&gt;$$|x^{\delta}_{\alpha} - \tilde{x}| = O(\delta^{2\mu/(2\mu + 1)})$$&lt;/p&gt;

&lt;h2 id=&quot;toc_1&quot;&gt;Iterative regularization method&lt;/h2&gt;

&lt;p&gt;For linear case, $Kx = y$, we only need to find Moore-Penrose pseudo-inverse $K^{\dagger}$, by minimizing $|Kx - y|^2$, the gradient based method will give negative gradient $K^{\dagger}(y - Kx)$, if we have that&lt;/p&gt;

&lt;p&gt;$$x = \phi(x) = x + K^{\dagger}(y - Kx)$$ is a contraction, then it would be nice to have an iterative scheme. However, contraction is a very rare property in nonlinear ill-posed problems, all we need to do here is to create some &lt;em&gt;nonexpansive&lt;/em&gt; operator $\phi$ which has contraction property.&lt;/p&gt;

&lt;h2 id=&quot;toc_2&quot;&gt;Nonlinear Landweber iteration&lt;/h2&gt;

&lt;p&gt;$$x_{k+1} = x_{k} + \tau F&amp;#39;(x_k)^{\ast}(y^{\delta} - F(x_k))$$&lt;/p&gt;

&lt;p&gt;The converging solution might not be the $x_0$-minimized solution.&lt;/p&gt;

&lt;h2 id=&quot;toc_3&quot;&gt;Modified nonlinear Landweber iteration&lt;/h2&gt;

&lt;p&gt;$$x_{k+1} = x_{k} + \tau F&amp;#39;(x_k)^{\ast}(y^{\delta} - F(x_k)) + \beta_k(x_0 - x_k)$$&lt;/p&gt;

&lt;p&gt;$\tau$ should be selected to be small enough.&lt;/p&gt;

&lt;h2 id=&quot;toc_4&quot;&gt;Newton type&lt;/h2&gt;

&lt;p&gt;Newton type methods are aiming to solve $$F&amp;#39;(x_k) (x_{k+1} - x_k) = y^{\delta} - F(x_k)$$&lt;/p&gt;

&lt;p&gt;Regularization is needed for most cases when ill-posedness are present, even for linearized case.&lt;/p&gt;

&lt;h2 id=&quot;toc_5&quot;&gt;Levenberg-Marquardt&lt;/h2&gt;

&lt;p&gt;Instead of minimizing usual squared misfit, this method goes one more step further, $$z_k = \arg\min_z |y^{\delta} - F(x_k) - F&amp;#39;(x_k)z| + \alpha_k |z|^2$$&lt;/p&gt;

&lt;p&gt;and $x_{k+1} =x_k + z_k$.&lt;/p&gt;

&lt;h2 id=&quot;toc_6&quot;&gt;Gauss-Newton&lt;/h2&gt;

&lt;p&gt;$$x_{k+1} = x_k + (F&amp;#39;(x_k)^{\ast} F&amp;#39;(x_k) + \alpha_k I)^{-1} (F&amp;#39;(x_k)^{\ast}(y^{\delta} - F(x_k)) + \alpha_k(x_0 - x_k)) $$ which is very similar to Levenberg-Marquardt.&lt;/p&gt;
</description>
        <pubDate>Mon, 13 Jun 2016 00:00:00 -0500</pubDate>
        <link>http://www.ma.utexas.edu/users/yzhong/2016/06/13/iterative-methods/</link>
        <guid isPermaLink="true">http://www.ma.utexas.edu/users/yzhong/2016/06/13/iterative-methods/</guid>
      </item>
    
  </channel>
</rss>